{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b8d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "Using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Using GPU:\", torch.backends.mps.is_available() if torch.backends.mps.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3876f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "MPS available : True\n",
      "tensor(-0.0002, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())   # will be False\n",
    "print(\"MPS available :\", torch.backends.mps.is_available())\n",
    "x = torch.randn(1000,1000, device=\"mps\")              # runs on Apple GPU\n",
    "\n",
    "print(x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323b4b1",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c92d1",
   "metadata": {},
   "source": [
    "A tensor is a mathematical object that generalizes scalars, vectors, and matrices to higher dimensions.\n",
    "In simple terms: it’s a multi-dimensional array of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e40d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar is a single number tensor\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48dbe82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094f5700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()\n",
    "#Get tesnor bacl as python int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab637ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector is a 1 dimensional tensor\n",
    "vector = torch.tensor([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503dd038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14a469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a96328eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae2f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MATRIX \n",
    "MATRIX = torch.tensor([[7,8],[9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d77b44de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim\n",
    "MATRIX[1]\n",
    "MATRIX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902643d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor\n",
    "TENSOR = torch.tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c6aa4",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "its the way NN learn is that they start with tensors full of random numbers and then adjust those random numbers to bettwe represent the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e1dab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d4d232a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3285, 0.6171, 0.0108, 0.9145],\n",
       "         [0.1910, 0.2074, 0.9460, 0.5330],\n",
       "         [0.1008, 0.3340, 0.0964, 0.7642]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1,3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd9b279c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a291017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224,224,3)) #H,W,color channels (R,G,B)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f78e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zeros and one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38b8f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f25466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d5051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d866064",
   "metadata": {},
   "source": [
    "## Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a88f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0], dtype=float, device =\"cpu\", requires_grad=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddfbead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3920f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6f4ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13af6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30bf0b",
   "metadata": {},
   "source": [
    "## Geeting info from tensor\n",
    "1. Tensor not right datatype\n",
    "2. Tensor not right shape\n",
    "3. Tensor not right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1277245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2165, 0.4991, 0.9121, 0.7154],\n",
       "        [0.4962, 0.1363, 0.8952, 0.2088],\n",
       "        [0.2183, 0.8548, 0.6766, 0.9148]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0c7866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698d4b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fcfb041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a51f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e364619",
   "metadata": {},
   "source": [
    "## Manipulating Tensors (tensor operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf781b5",
   "metadata": {},
   "source": [
    "Include addition, sub, multiplicatoion (element - wise) division and matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba02a18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfcbc74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6853b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4504918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e0f52e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.mul( 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc8387",
   "metadata": {},
   "source": [
    "## Finding the min, max, sum etc tensor aggreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b006ae43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(0,100,10)\n",
    "x\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f14203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caae56d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e07ff834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mean cant take int 64 dtype so need to convert dtype to calcualte mean\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72cb5a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x) , x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a69c358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argmax and argmin\n",
    "# find positioon in tensor that has min or max value that returns index postion of target tensor where min or max value is located\n",
    "torch.argmax(x), x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3b9a864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(x), x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31096212",
   "metadata": {},
   "source": [
    "## Reshaping, stakcing, squeezing and unsqueezing tensors\n",
    "### Reshaping: respahes input tensor to a defined tensor\n",
    "### View - Returen a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "### Stacking - combine multile tensors on top of each other (vtsack) or side by side (hstack)\n",
    "### Squeeze - remove all  '1' from dimension from a tensor (single dimensions)\n",
    "### Unsqueeze - add a  1 to a target ttensor \n",
    "### Permute: Retuern a view of the input with dimenesios permuted(swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3aa4b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1. ,10.) # . makes it a float tensor\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3beaba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(9,1)\n",
    "x_reshaped, x_reshaped.shape\n",
    "# compantiable beacise 1* 9 is 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b09a945",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 4]' is invalid for input of size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m y, y\u001b[38;5;241m.\u001b[39mshape, y_reshaped, y_reshaped\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m15.\u001b[39m)   \u001b[38;5;66;03m# 14 elements\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m             \u001b[38;5;66;03m# needs 12\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 4]' is invalid for input of size 14"
     ]
    }
   ],
   "source": [
    "# if we change to \n",
    "y = torch.arange(1., 13.)\n",
    "y_reshaped = y.reshape(3,4)\n",
    "\n",
    "y, y.shape, y_reshaped, y_reshaped.shape\n",
    "\n",
    "y = torch.arange(1., 15.)   # 14 elements\n",
    "y.reshape(3, 4)             # needs 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2654e640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chnage the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca59ca44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z chanes x (beacuse they share the same memory as the original tensor)\n",
    "z[:,0] = 5 # synatax: \t•\t: → all rows\n",
    "                    # \t•\t0 → first column\n",
    "\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9296eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7.],\n",
       "         [8., 8., 8., 8.],\n",
       "         [9., 9., 9., 9.]]),\n",
       " torch.Size([9, 4]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack \n",
    "x_stacked = torch.stack([x,x,x,x], dim = 1)\n",
    "'''\n",
    "dim=0 → stack vertically\n",
    "\n",
    "Like rows added.\n",
    "\n",
    "dim=1 → stack horizontally\n",
    "\n",
    "'''\n",
    "x_stacked, x_stacked.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32466aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze removes all single dimensions from a target tensor\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d2e8a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a6679c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_squeeze = x_reshaped.squeeze() # changed dim from [[]] to []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01ea5f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "751de667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]) and shape is torch.Size([9])\n",
      "unsqueezed at dim 0: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]) and shape is torch.Size([1, 9])\n",
      "unsqueezed at dim 1: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]]) and shape is torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# unsqueuze adds a single dimension to a target tensor at a specified dim\n",
    "\n",
    "print(f\"previous target: {x_squeeze} and shape is {x_squeeze.shape}\")\n",
    "print(f\"unsqueezed at dim 0: {x_squeeze.unsqueeze(dim=0)} and shape is {x_squeeze.unsqueeze(dim=0).shape}\")\n",
    "print(f\"unsqueezed at dim 1: {x_squeeze.unsqueeze(dim=1)} and shape is {x_squeeze.unsqueeze(dim=0).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6a96926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permuste: rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224,224,3)) #H,W,color channels (R,G,B)\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0 to 2, 1 to 0, 2 to 1\n",
    "x_original.shape, x_permuted.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8920c289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46748736.)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0,0,0] = 46748738\n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "x_permuted[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fc1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
